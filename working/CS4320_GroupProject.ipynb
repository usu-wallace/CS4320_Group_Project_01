{"cells":[{"cell_type":"code","execution_count":201,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2023-10-11T02:09:31.921526Z","iopub.status.busy":"2023-10-11T02:09:31.921101Z","iopub.status.idle":"2023-10-11T02:09:31.929521Z","shell.execute_reply":"2023-10-11T02:09:31.928533Z","shell.execute_reply.started":"2023-10-11T02:09:31.921499Z"},"trusted":true},"outputs":[],"source":["import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","import matplotlib.pyplot as plt\n","from sklearn.compose import ColumnTransformer, make_column_transformer\n","from sklearn.dummy import DummyClassifier\n","from sklearn.impute import SimpleImputer\n","from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.pipeline import Pipeline, make_pipeline\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n","from sklearn.svm import SVC\n","from sklearn.tree import DecisionTreeClassifier"]},{"cell_type":"markdown","metadata":{},"source":["## Dummy Submission (All-Positive)"]},{"cell_type":"code","execution_count":202,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T02:09:31.932386Z","iopub.status.busy":"2023-10-11T02:09:31.931701Z","iopub.status.idle":"2023-10-11T02:09:31.943552Z","shell.execute_reply":"2023-10-11T02:09:31.942640Z","shell.execute_reply.started":"2023-10-11T02:09:31.932356Z"},"trusted":true},"outputs":[],"source":["def dummy_submit():\n","    submission_df = pd.read_csv('../input/spaceship-titanic/sample_submission.csv')\n","    submission_df['Transported'] = True\n","    submission_df.to_csv('submission.csv', index=False)\n","    \n","# This is dummy, not real submit, comment out when you don't want dummy\n","# dummy_submit()"]},{"cell_type":"markdown","metadata":{},"source":["# Pre-processing"]},{"cell_type":"code","execution_count":224,"metadata":{},"outputs":[],"source":["train_df = pd.read_csv('../input/spaceship-titanic/train.csv')\n","test_df = pd.read_csv('../input/spaceship-titanic/test.csv') # Does NOT contain y -> 'Transported'\n","\n","# Replaces whitespace with NaN\n","train_df.replace(r'^\\s+$', np.nan, regex=True) \n","test_df.replace(r'^\\s+$', np.nan, regex=True)\n","\n","def splitData(dataframe):\n","    # Split \"PassengerId\" into \"GroupId\" & \"IndividualId\"\n","    dataframe[\"GroupId\"] = dataframe[\"PassengerId\"].str.split(\"_\").str[0]\n","    dataframe[\"IndividualId\"] = dataframe[\"PassengerId\"].str.split(\"_\").str[1]\n","\n","    dataframe[\"GroupId\"] = pd.to_numeric(dataframe[\"GroupId\"], errors=\"ignore\", downcast=\"integer\")\n","    dataframe[\"IndividualId\"] = pd.to_numeric(dataframe[\"IndividualId\"], errors=\"ignore\", downcast=\"integer\")\n","\n","    # Split \"Cabin\" into \"Deck\", \"Number\", & \"Side\"\n","    dataframe[\"Deck\"] = dataframe[\"Cabin\"].str.split(\"/\").str[0]\n","    dataframe[\"Number\"] = dataframe[\"Cabin\"].str.split(\"/\").str[1]\n","    dataframe[\"Side\"] = dataframe[\"Cabin\"].str.split(\"/\").str[2]\n","\n","    dataframe.shape\n","    dataframe.sort_index()\n","\n","    return dataframe\n","\n","train_df = splitData(train_df)\n","test_df = splitData(test_df)"]},{"cell_type":"code","execution_count":261,"metadata":{},"outputs":[],"source":["numeric_features = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"GroupId\", \"Number\"] \n","# categorical_features = [\"HomePlanet\", \"Destination\", \"Deck\", \"CryoSleep\", \"VIP\", \"Side\"]\n","# drop_features = [\"Name\", \"PassengerId\", \"IndividualId\", \"Cabin\"]  # do not include these features in modeling\n","categorical_features = [\"HomePlanet\", \"Destination\", \"Deck\", \"CryoSleep\", \"VIP\", \"Side\", \"IndividualId\"]\n","drop_features = [\"Name\", \"PassengerId\", \"Cabin\"]  # do not include these features in modeling\n","passthrough_features = [] # do not apply any transformation\n","\n","target = \"Transported\"\n","\n","X_train = train_df.drop(columns=[target, *drop_features])\n","y_train = train_df[target]\n","\n","X_test = test_df.drop(columns=[*drop_features]) # test_df does NOT contain target"]},{"cell_type":"code","execution_count":270,"metadata":{},"outputs":[],"source":["def fillVIP(dataframe):\n","    BEFORE = dataframe[\"VIP\"].isnull().sum() # The print statement below doesn't like this inside it.\n","    print(f\"Number of empty VIP cells BEFORE: { BEFORE }\")\n","\n","    # No passenger under the age 18 is a VIP\n","    ageVIPIndex = dataframe[(dataframe[\"VIP\"].isnull() == True) & (dataframe[\"Age\"] < 18)][[\"VIP\"]].index\n","    dataframe[\"VIP\"][ageVIPIndex] = False\n","\n","    # No passenger from Earth is a VIP\n","    earthVIPIndex = dataframe[(dataframe[\"VIP\"].isnull() == True) & (dataframe[\"HomePlanet\"] == \"Earth\")][[\"VIP\"]].index\n","    dataframe[\"VIP\"][earthVIPIndex] = False\n","\n","    AFTER = dataframe[\"VIP\"].isnull().sum()\n","    print(f\"Number of empty VIP cells AFTER: { AFTER }\")"]},{"cell_type":"code","execution_count":278,"metadata":{},"outputs":[],"source":["def fillGroup(dataframe):\n","    HPBEFORE = dataframe[\"HomePlanet\"].isnull().sum()\n","    DESTBEFORE = dataframe[\"Destination\"].isnull().sum()\n","    print(f\"Number of empty HomePlanet cells BEFORE: { HPBEFORE }\")\n","    print(f\"Number of empty Destination cells BEFORE: { DESTBEFORE }\")\n","\n","    # A passenger in a group will have the same HomePlanet and Destination as everyone else in their group\n","    HPIndex = dataframe[(dataframe[\"HomePlanet\"].isnull() == True)].index\n","    DESTIndex = dataframe[(dataframe[\"Destination\"].isnull() == True)].index\n","\n","    for i in HPIndex:\n","        if (dataframe[\"GroupId\"][i] == dataframe[\"GroupId\"][i-1]):\n","            dataframe.at[i, \"HomePlanet\"] = dataframe.at[i-1, \"HomePlanet\"]\n","        elif (dataframe[\"GroupId\"][i] == dataframe[\"GroupId\"][i+1]):\n","            dataframe.at[i, \"HomePlanet\"] = dataframe.at[i+1, \"HomePlanet\"]\n","    for i in DESTIndex:\n","        if (dataframe[\"GroupId\"][i] == dataframe[\"GroupId\"][i-1]):\n","            dataframe.at[i, \"Destination\"] = dataframe.at[i-1, \"Destination\"]\n","        elif (dataframe[\"GroupId\"][i] == dataframe[\"GroupId\"][i+1]):\n","            dataframe.at[i, \"Destination\"] = dataframe.at[i+1, \"Destination\"]        \n","\n","    # A passenger in a group will have the same Cabin as everyone else in their group\n","    DECKBEFORE = dataframe[\"Deck\"].isnull().sum()\n","    print(f\"Number of empty Cabin cells BEFORE: { DECKBEFORE }\")\n","    \n","    deckIndex = dataframe[(dataframe[\"Deck\"].isnull() == True)].index\n","\n","    for i in deckIndex:\n","        if (dataframe[\"GroupId\"][i] == dataframe[\"GroupId\"][i-1]):\n","            dataframe.at[i, \"Deck\"] = dataframe.at[i-1, \"Deck\"]\n","            dataframe.at[i, \"Number\"] = dataframe.at[i-1, \"Number\"]\n","            dataframe.at[i, \"Side\"] = dataframe.at[i-1, \"Side\"]\n","        elif (dataframe[\"GroupId\"][i] == dataframe[\"GroupId\"][i+1]):\n","            dataframe.at[i, \"Deck\"] = dataframe.at[i+1, \"Deck\"]\n","            dataframe.at[i, \"Number\"] = dataframe.at[i+1, \"Number\"]\n","            dataframe.at[i, \"Side\"] = dataframe.at[i+1, \"Side\"]            \n","    \n","    HPAFTER = dataframe[\"HomePlanet\"].isnull().sum()\n","    DESTAFTER = dataframe[\"Destination\"].isnull().sum()\n","    DECKAFTER = dataframe[\"Deck\"].isnull().sum()\n","    print(f\"Number of empty HomePlanet cells AFTER: { HPAFTER }\")\n","    print(f\"Number of empty Destination cells AFTER: { DESTAFTER }\")\n","    print(f\"Number of empty Cabin cells AFTER: { DECKAFTER }\")"]},{"cell_type":"code","execution_count":279,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of empty VIP cells BEFORE: 203\n","Number of empty VIP cells AFTER: 76\n","Number of empty HomePlanet cells BEFORE: 201\n","Number of empty Destination cells BEFORE: 182\n","Number of empty Cabin cells BEFORE: 199\n","Number of empty HomePlanet cells AFTER: 111\n","Number of empty Destination cells AFTER: 103\n","Number of empty Cabin cells AFTER: 99\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_347/4159784907.py:7: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  dataframe[\"VIP\"][ageVIPIndex] = False\n","/tmp/ipykernel_347/4159784907.py:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  dataframe[\"VIP\"][earthVIPIndex] = False\n"]},{"name":"stdout","output_type":"stream","text":["Number of empty VIP cells BEFORE: 49\n","Number of empty VIP cells AFTER: 49\n","Number of empty HomePlanet cells BEFORE: 46\n","Number of empty Destination cells BEFORE: 51\n","Number of empty Cabin cells BEFORE: 63\n","Number of empty HomePlanet cells AFTER: 46\n","Number of empty Destination cells AFTER: 51\n","Number of empty Cabin cells AFTER: 63\n"]},{"name":"stderr","output_type":"stream","text":["/tmp/ipykernel_347/4159784907.py:7: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  dataframe[\"VIP\"][ageVIPIndex] = False\n","/tmp/ipykernel_347/4159784907.py:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  dataframe[\"VIP\"][earthVIPIndex] = False\n"]}],"source":["X_trainCPY = X_train.copy()\n","\n","fillVIP(X_trainCPY)\n","fillGroup(X_trainCPY)\n","\n","X_trainCPY.to_csv('test.csv', index=False)\n","fillVIP(X_test)\n","fillGroup(X_test)"]},{"cell_type":"markdown","metadata":{},"source":["### Create Column Transformer"]},{"cell_type":"code","execution_count":276,"metadata":{"execution":{"iopub.execute_input":"2023-10-11T02:09:32.156798Z","iopub.status.busy":"2023-10-11T02:09:32.156416Z","iopub.status.idle":"2023-10-11T02:09:32.175263Z","shell.execute_reply":"2023-10-11T02:09:32.174310Z","shell.execute_reply.started":"2023-10-11T02:09:32.156755Z"},"trusted":true},"outputs":[],"source":["preprocessor = make_column_transformer(\n","    (make_pipeline(\n","        SimpleImputer(missing_values=np.nan, strategy=\"mean\"),\n","        StandardScaler() \n","        ), numeric_features \n","    ),\n","    (make_pipeline(\n","        SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\"), \n","        OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n","        ), categorical_features\n","    ),\n","    remainder='passthrough'  # Keep non-transformed columns\n",")"]},{"cell_type":"code","execution_count":273,"metadata":{},"outputs":[],"source":["\n","\n","# from class code\n","def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n","    \"\"\"\n","    Returns mean and std of cross validation\n","\n","    Parameters\n","    ----------\n","    model :\n","        scikit-learn model\n","    X_train : numpy array or pandas DataFrame\n","        X in the training data\n","    y_train :\n","        y in the training data\n","\n","    Returns\n","    ----------\n","        pandas Series with mean scores from cross_validation\n","    \"\"\"\n","\n","    scores = cross_validate(model, X_train, y_train, **kwargs)\n","\n","    mean_scores = pd.DataFrame(scores).mean()\n","    std_scores = pd.DataFrame(scores).std()\n","    out_col = []\n","\n","    for i in range(len(mean_scores)):\n","        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n","\n","    return pd.Series(data=out_col, index=mean_scores.index)"]},{"cell_type":"code","execution_count":277,"metadata":{},"outputs":[],"source":["knn = False\n","\n","if knn :\n","    testpipeline = make_pipeline(preprocessor, KNeighborsClassifier())\n","else:\n","    testpipeline = make_pipeline(preprocessor, SVC())\n","\n","testpipeline.fit(X_train, y_train)\n","y_test = testpipeline.predict(X_test)\n","\n","submission_df = pd.read_csv('../input/spaceship-titanic/sample_submission.csv')\n","submission_df['Transported'] = y_test\n","submission_df.to_csv('submission.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.5"}},"nbformat":4,"nbformat_minor":4}
