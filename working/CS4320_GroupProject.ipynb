{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "execution": {
          "iopub.execute_input": "2023-10-11T02:09:31.921526Z",
          "iopub.status.busy": "2023-10-11T02:09:31.921101Z",
          "iopub.status.idle": "2023-10-11T02:09:31.929521Z",
          "shell.execute_reply": "2023-10-11T02:09:31.928533Z",
          "shell.execute_reply.started": "2023-10-11T02:09:31.921499Z"
        },
        "trusted": true,
        "id": "WVuLbkbPqWQf"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.model_selection import cross_val_score, cross_validate, train_test_split\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler, OrdinalEncoder\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fQMHLGq6qWQi"
      },
      "source": [
        "## Dummy Submission (All-Positive)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T02:09:31.932386Z",
          "iopub.status.busy": "2023-10-11T02:09:31.931701Z",
          "iopub.status.idle": "2023-10-11T02:09:31.943552Z",
          "shell.execute_reply": "2023-10-11T02:09:31.942640Z",
          "shell.execute_reply.started": "2023-10-11T02:09:31.932356Z"
        },
        "trusted": true,
        "id": "8GMQX6_CqWQj"
      },
      "outputs": [],
      "source": [
        "def dummy_submit():\n",
        "    submission_df = pd.read_csv('../input/spaceship-titanic/sample_submission.csv')\n",
        "    submission_df['Transported'] = True\n",
        "    submission_df.to_csv('submission.csv', index=False)\n",
        "\n",
        "# This is dummy, not real submit, comment out when you don't want dummy\n",
        "# dummy_submit()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDF9bckOqWQk"
      },
      "source": [
        "# Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "avXrDkvWqWQk"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv('train.csv')\n",
        "test_df = pd.read_csv('test.csv') # Does NOT contain y -> 'Transported'\n",
        "\n",
        "# Replaces whitespace with NaN\n",
        "train_df.replace(r'^\\s+$', np.nan, regex=True)\n",
        "test_df.replace(r'^\\s+$', np.nan, regex=True)\n",
        "\n",
        "def splitData(dataframe):\n",
        "    # Split \"PassengerId\" into \"GroupId\" & \"IndividualId\"\n",
        "    dataframe[\"GroupId\"] = dataframe[\"PassengerId\"].str.split(\"_\").str[0]\n",
        "    dataframe[\"IndividualId\"] = dataframe[\"PassengerId\"].str.split(\"_\").str[1]\n",
        "\n",
        "    # Split \"Cabin\" into \"Deck\", \"Number\", & \"Side\"\n",
        "    dataframe[\"Deck\"] = dataframe[\"Cabin\"].str.split(\"/\").str[0]\n",
        "    dataframe[\"Number\"] = dataframe[\"Cabin\"].str.split(\"/\").str[1]\n",
        "    dataframe[\"Side\"] = dataframe[\"Cabin\"].str.split(\"/\").str[2]\n",
        "\n",
        "    dataframe.shape\n",
        "    dataframe.sort_index()\n",
        "\n",
        "    return dataframe\n",
        "\n",
        "train_df = splitData(train_df)\n",
        "test_df = splitData(test_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "id": "86P-vF6IqWQl"
      },
      "outputs": [],
      "source": [
        "numeric_features = [\"Age\", \"RoomService\", \"FoodCourt\", \"ShoppingMall\", \"Spa\", \"VRDeck\", \"GroupId\", \"Number\"]\n",
        "categorical_features = [\"HomePlanet\", \"Destination\", \"Deck\", \"CryoSleep\", \"VIP\", \"Side\"]\n",
        "drop_features = [\"Name\", \"PassengerId\", \"IndividualId\", \"Cabin\"]  # do not include these features in modeling\n",
        "passthrough_features = [] # do not apply any transformation\n",
        "\n",
        "target = \"Transported\"\n",
        "\n",
        "X_train = train_df.drop(columns=[target, *drop_features])\n",
        "y_train = train_df[target]\n",
        "\n",
        "X_test = test_df.drop(columns=[*drop_features]) # test_df does NOT contain target"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def fillSpend(dataframe, feature):\n",
        "    spend_index = dataframe[\n",
        "      (dataframe[feature].isnull() == True) &\n",
        "      ((dataframe[\"Age\"]<13) | (dataframe[\"CryoSleep\"] == True))\n",
        "    ].index\n",
        "    dataframe[feature][spend_index] = 0\n",
        "\n",
        "\n",
        "testTrain = train_df\n",
        "testTest = test_df\n",
        "AllData = pd.concat([train_df, test_df], ignore_index=True)\n",
        "\n",
        "def run(df):\n",
        "  print(df[\"Spa\"].isnull().sum())\n",
        "  print(df[\"VRDeck\"].isnull().sum())\n",
        "  print(df[\"ShoppingMall\"].isnull().sum())\n",
        "  print(df[\"FoodCourt\"].isnull().sum())\n",
        "  print(df[\"RoomService\"].isnull().sum())\n",
        "\n",
        "  spend_list = [\"Spa\", \"RoomService\", \"FoodCourt\", \"VRDeck\", \"ShoppingMall\"]\n",
        "  for i in spend_list:\n",
        "      fillSpend(df, i)\n",
        "\n",
        "  print(\"--------\")\n",
        "  print(df[\"Spa\"].isnull().sum())\n",
        "  print(df[\"VRDeck\"].isnull().sum())\n",
        "  print(df[\"ShoppingMall\"].isnull().sum())\n",
        "  print(df[\"FoodCourt\"].isnull().sum())\n",
        "  print(df[\"RoomService\"].isnull().sum(),\"\\n\")\n",
        "\n",
        "\n",
        "print(\"First, train_df\")\n",
        "run(testTrain)\n",
        "\n",
        "print(\"Next, test_df\")\n",
        "run(testTest)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mZY72x_BrhKD",
        "outputId": "8fcbde5f-f2ad-4be0-9389-f456c4a19629"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First, train_df\n",
            "183\n",
            "188\n",
            "208\n",
            "183\n",
            "181\n",
            "--------\n",
            "114\n",
            "107\n",
            "103\n",
            "106\n",
            "107 \n",
            "\n",
            "Next, test_df\n",
            "101\n",
            "80\n",
            "98\n",
            "106\n",
            "82\n",
            "--------\n",
            "52\n",
            "43\n",
            "60\n",
            "65\n",
            "55 \n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-74-9f3b1b95ec4a>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataframe[feature][spend_index] = 0\n",
            "<ipython-input-74-9f3b1b95ec4a>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataframe[feature][spend_index] = 0\n",
            "<ipython-input-74-9f3b1b95ec4a>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataframe[feature][spend_index] = 0\n",
            "<ipython-input-74-9f3b1b95ec4a>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataframe[feature][spend_index] = 0\n",
            "<ipython-input-74-9f3b1b95ec4a>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataframe[feature][spend_index] = 0\n",
            "<ipython-input-74-9f3b1b95ec4a>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataframe[feature][spend_index] = 0\n",
            "<ipython-input-74-9f3b1b95ec4a>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataframe[feature][spend_index] = 0\n",
            "<ipython-input-74-9f3b1b95ec4a>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataframe[feature][spend_index] = 0\n",
            "<ipython-input-74-9f3b1b95ec4a>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataframe[feature][spend_index] = 0\n",
            "<ipython-input-74-9f3b1b95ec4a>:6: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  dataframe[feature][spend_index] = 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AR7zc1VmqWQm"
      },
      "source": [
        "### Create Column Transformer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2023-10-11T02:09:32.156798Z",
          "iopub.status.busy": "2023-10-11T02:09:32.156416Z",
          "iopub.status.idle": "2023-10-11T02:09:32.175263Z",
          "shell.execute_reply": "2023-10-11T02:09:32.174310Z",
          "shell.execute_reply.started": "2023-10-11T02:09:32.156755Z"
        },
        "trusted": true,
        "id": "MM9VF_AKqWQn"
      },
      "outputs": [],
      "source": [
        "preprocessor = make_column_transformer(\n",
        "    (make_pipeline(\n",
        "        SimpleImputer(missing_values=np.nan, strategy=\"mean\"),\n",
        "        StandardScaler()\n",
        "        ), numeric_features\n",
        "    ),\n",
        "    (make_pipeline(\n",
        "        SimpleImputer(missing_values=np.nan, strategy=\"most_frequent\"),\n",
        "        OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
        "        ), categorical_features\n",
        "    ),\n",
        "    remainder='passthrough'  # Keep non-transformed columns\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "XPTkW78IqWQo"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# from class code\n",
        "def mean_std_cross_val_scores(model, X_train, y_train, **kwargs):\n",
        "    \"\"\"\n",
        "    Returns mean and std of cross validation\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    model :\n",
        "        scikit-learn model\n",
        "    X_train : numpy array or pandas DataFrame\n",
        "        X in the training data\n",
        "    y_train :\n",
        "        y in the training data\n",
        "\n",
        "    Returns\n",
        "    ----------\n",
        "        pandas Series with mean scores from cross_validation\n",
        "    \"\"\"\n",
        "\n",
        "    scores = cross_validate(model, X_train, y_train, **kwargs)\n",
        "\n",
        "    mean_scores = pd.DataFrame(scores).mean()\n",
        "    std_scores = pd.DataFrame(scores).std()\n",
        "    out_col = []\n",
        "\n",
        "    fillSpend(std_scores)\n",
        "    for i in range(len(mean_scores)):\n",
        "        out_col.append((f\"%0.3f (+/- %0.3f)\" % (mean_scores[i], std_scores[i])))\n",
        "\n",
        "    return pd.Series(data=out_col, index=mean_scores.index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "hYJl3HQhqWQp"
      },
      "outputs": [],
      "source": [
        "knn = False\n",
        "\n",
        "if knn :\n",
        "    testpipeline = make_pipeline(preprocessor, KNeighborsClassifier())\n",
        "else:\n",
        "    testpipeline = make_pipeline(preprocessor, SVC())\n",
        "\n",
        "testpipeline.fit(X_train, y_train)\n",
        "y_test = testpipeline.predict(X_test)\n",
        "\n",
        "submission_df = pd.read_csv('../input/spaceship-titanic/sample_submission.csv')\n",
        "submission_df['Transported'] = y_test\n",
        "submission_df.to_csv('submission.csv', index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aSlxJAD3rDm1"
      },
      "execution_count": 18,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}